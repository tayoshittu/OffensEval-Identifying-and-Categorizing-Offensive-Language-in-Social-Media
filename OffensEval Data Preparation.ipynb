{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id                                              tweet subtask_a  \\\n",
      "0      86426  @USER She should ask a few native Americans wh...       OFF   \n",
      "1      90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       OFF   \n",
      "2      16820  Amazon is investigating Chinese employees who ...       NOT   \n",
      "3      62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n",
      "4      43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n",
      "...      ...                                                ...       ...   \n",
      "13235  95338  @USER Sometimes I get strong vibes from people...       OFF   \n",
      "13236  67210  Benidorm ✅  Creamfields ✅  Maga ✅   Not too sh...       NOT   \n",
      "13237  82921  @USER And why report this garbage.  We don't g...       OFF   \n",
      "13238  27429                                        @USER Pussy       OFF   \n",
      "13239  46552  #Spanishrevenge vs. #justice #HumanRights and ...       NOT   \n",
      "\n",
      "      subtask_b subtask_c  \n",
      "0           UNT       NaN  \n",
      "1           TIN       IND  \n",
      "2           NaN       NaN  \n",
      "3           UNT       NaN  \n",
      "4           NaN       NaN  \n",
      "...         ...       ...  \n",
      "13235       TIN       IND  \n",
      "13236       NaN       NaN  \n",
      "13237       TIN       OTH  \n",
      "13238       UNT       NaN  \n",
      "13239       NaN       NaN  \n",
      "\n",
      "[13240 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "train_data=pd.read_csv('olid-training-v1.0.tsv', delimiter='\\t', encoding='utf-8')\n",
    "\n",
    "train_tweets = train_data[['tweet']] #Extract tweets\n",
    "train_task_a_labels= train_data[['subtask_a']] #Extract subtsak_a labels\n",
    "train_task_b_labels= train_data[['subtask_b']] #Extract subtsak_b labels\n",
    "train_task_c_labels= train_data[['subtask_c']] #Extract subtsak_c labels\n",
    "\n",
    "train_task_a_labels.columns.values[0] = 'class_a' #Rename class attribute\n",
    "train_task_b_labels.columns.values[0] = 'class_b' #Rename class attribute\n",
    "train_task_c_labels.columns.values[0] = 'class_c' #Rename class attribute\n",
    "\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to clean tweets in a data frame's tweet column\n",
    "def clean_tweets(df):\n",
    "    \n",
    "    punctuations = string.punctuation\n",
    "    \n",
    "    df.loc[:, 'tweet'] = df.tweet.str.replace('@USER', '') #Remove mentions (@USER)\n",
    "    df.loc[:, 'tweet'] = df.tweet.str.replace('URL', '') #Remove URLs\n",
    "    df.loc[:, 'tweet'] = df.tweet.str.replace('&amp', 'and') #Replace ampersand (&) with and\n",
    "    df.loc[:, 'tweet'] = df.tweet.str.replace('&lt','') #Remove &lt\n",
    "    df.loc[:, 'tweet'] = df.tweet.str.replace('&gt','') #Remove &gt\n",
    "    df.loc[:, 'tweet'] = df.tweet.str.replace('\\d+','') #Remove numbers\n",
    "\n",
    "    #Remove punctuations\n",
    "    for punctuation in punctuations:\n",
    "        df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
    "\n",
    "    df.loc[:, 'tweet'] = df.astype(str).apply(\n",
    "        lambda x: x.str.encode('ascii', 'ignore').str.decode('ascii')\n",
    "    ) #Remove emojis\n",
    "    df.loc[:, 'tweet'] = df.tweet.str.strip() #Trim leading and trailing whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets(train_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_task_a_data = train_tweets.join(train_task_a_labels)\n",
    "\n",
    "train_task_b_data = train_tweets.join(train_task_b_labels)\n",
    "train_task_b_data = train_task_b_data.dropna() #Drop records with missing values\n",
    "\n",
    "train_task_c_data = train_tweets.join(train_task_c_labels)\n",
    "train_task_c_data = train_task_c_data.dropna() #Drop records with missing values\n",
    "\n",
    "#Apply quotes to cleaned tweets\n",
    "train_task_a_data.update(train_task_a_data[['tweet']].applymap('\\'{}\\''.format))\n",
    "train_task_b_data.update(train_task_b_data[['tweet']].applymap('\\'{}\\''.format))\n",
    "train_task_c_data.update(train_task_c_data[['tweet']].applymap('\\'{}\\''.format))\n",
    "\n",
    "# train_task_a_data.to_csv('olid_training_a.csv', index=None)\n",
    "# train_task_b_data.to_csv('olid_training_b.csv', index=None)\n",
    "# train_task_c_data.to_csv('olid_training_c.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   tweet class_a\n",
      "0      'She should ask a few native Americans what th...     OFF\n",
      "1                      'Go home youre drunk  MAGA Trump'     OFF\n",
      "2      'Amazon is investigating Chinese employees who...     NOT\n",
      "3      'Someone shouldveTaken this piece of shit to a...     OFF\n",
      "4      'Obama wanted liberals and illegals to move in...     NOT\n",
      "...                                                  ...     ...\n",
      "13235  'Sometimes I get strong vibes from people and ...     OFF\n",
      "13236  'Benidorm   Creamfields   Maga    Not too shab...     NOT\n",
      "13237  'And why report this garbage  We dont give a c...     OFF\n",
      "13238                                            'Pussy'     OFF\n",
      "13239  'Spanishrevenge vs justice HumanRights and Fre...     NOT\n",
      "\n",
      "[13240 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_task_a_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet class_a\n",
      "0  'WhoIsQ WheresTheServer DumpNike DECLASFISA De...     OFF\n",
      "1  'ConstitutionDay is revered by Conservatives h...     NOT\n",
      "2  'FOXNews NRA MAGA POTUS TRUMP ndAmendment RNC ...     NOT\n",
      "3  'Watching Boomer getting the news that she is ...     NOT\n",
      "4  'NoPasaran Unity demo to oppose the farright i...     OFF\n"
     ]
    }
   ],
   "source": [
    "#Read tweets from test sets\n",
    "test_tweet_a=pd.read_csv('testset-levela.tsv', delimiter='\\t', encoding='utf-8')\n",
    "test_tweet_b=pd.read_csv('testset-levelb.tsv', delimiter='\\t', encoding='utf-8')\n",
    "test_tweet_c=pd.read_csv('testset-levelc.tsv', delimiter='\\t', encoding='utf-8')\n",
    "\n",
    "#Read tweet labels\n",
    "test_label_a=pd.read_csv('labels-levela.csv', encoding='utf-8', \n",
    "                         index_col=False, names=['id', 'class_a'])\n",
    "test_label_b=pd.read_csv('labels-levelb.csv', encoding='utf-8', \n",
    "                         index_col=False, names=['id', 'class_b'])\n",
    "test_label_c=pd.read_csv('labels-levelc.csv', encoding='utf-8', \n",
    "                         index_col=False, names=['id', 'class_c'])\n",
    "\n",
    "#Merge tweets with labels by id\n",
    "test_tweet_a = test_tweet_a.merge(test_label_a, on='id')\n",
    "test_tweet_b = test_tweet_b.merge(test_label_b, on='id')\n",
    "test_tweet_c = test_tweet_c.merge(test_label_c, on='id')\n",
    "\n",
    "#Drop id column\n",
    "test_tweet_a = test_tweet_a.drop(columns='id')\n",
    "test_tweet_b = test_tweet_b.drop(columns='id')\n",
    "test_tweet_c = test_tweet_c.drop(columns='id')\n",
    "\n",
    "#Clean tweets in test sets\n",
    "clean_tweets(test_tweet_a)\n",
    "clean_tweets(test_tweet_b)\n",
    "clean_tweets(test_tweet_c)\n",
    "\n",
    "#Apply quotes to cleaned tweets\n",
    "test_tweet_a.update(test_tweet_a[['tweet']].applymap('\\'{}\\''.format))\n",
    "test_tweet_b.update(test_tweet_b[['tweet']].applymap('\\'{}\\''.format))\n",
    "test_tweet_c.update(test_tweet_c[['tweet']].applymap('\\'{}\\''.format))\n",
    "\n",
    "\n",
    "#Export to csv file\n",
    "# test_tweet_a.to_csv('olid_test_a.csv', index=None,header=True)\n",
    "# test_tweet_b.to_csv('olid_test_b.csv', index=None, header=True)\n",
    "# test_tweet_c.to_csv('olid_test_c.csv', index=None, header=True)\n",
    "\n",
    "print(test_tweet_a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 tweet class_a\n",
      "0    'WhoIsQ WheresTheServer DumpNike DECLASFISA De...     OFF\n",
      "1    'ConstitutionDay is revered by Conservatives h...     NOT\n",
      "2    'FOXNews NRA MAGA POTUS TRUMP ndAmendment RNC ...     NOT\n",
      "3    'Watching Boomer getting the news that she is ...     NOT\n",
      "4    'NoPasaran Unity demo to oppose the farright i...     OFF\n",
      "..                                                 ...     ...\n",
      "855  'DespicableDems lie again about rifles Dem Dis...     OFF\n",
      "856  'MeetTheSpeakers   will present in our event O...     NOT\n",
      "857  'people just unfollowed me for talking about m...     OFF\n",
      "858  'WednesdayWisdom Antifa calls the right fascis...     NOT\n",
      "859            'Kavanaugh typical liberals  Democrats'     NOT\n",
      "\n",
      "[860 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_tweet_a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
